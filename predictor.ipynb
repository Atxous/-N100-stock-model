{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/2008_Global_Markets_Data.csv\")\n",
    "for x in (2009, 2023):\n",
    "    df = pd.concat([df, pd.read_csv(f\"data/{x}_Global_Markets_Data.csv\")], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.set_index(\"Date\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8*len(df))\n",
    "\n",
    "x_train = df.select_dtypes(include = np.number)[:train_size].astype(np.float32)\n",
    "x_valid = df.select_dtypes(include = np.number)[train_size:int(0.9*len(df))].astype(np.float32)\n",
    "x_test = df.select_dtypes(include = np.number)[int(0.9*len(df)):].astype(np.float32)\n",
    "\n",
    "x_train[\"Ticker\"] = df[\"Ticker\"][:train_size]\n",
    "x_valid[\"Ticker\"] = df[\"Ticker\"][train_size:int(0.9*len(df))]\n",
    "x_test[\"Ticker\"] = df[\"Ticker\"][int(0.9*len(df)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n100_train = x_train[x_train[\"Ticker\"] == \"^N100\"].drop(\"Ticker\", axis = 1)\n",
    "n100_valid = x_valid[x_valid[\"Ticker\"] == \"^N100\"].drop(\"Ticker\", axis = 1)\n",
    "n100_test = x_test[x_test[\"Ticker\"] == \"^N100\"].drop(\"Ticker\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = n100_train.values.mean(0), n100_train.values.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, input_seq, window_length, transform = None):\n",
    "        self.input_seq = input_seq\n",
    "        self.window_length = window_length\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_seq) - self.window_length * 2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        window = idx + self.window_length\n",
    "        seq = (np.array(self.input_seq[idx:window]) - mean) / std\n",
    "        target_seq = (np.array(self.input_seq[window:window + self.window_length]) - mean) / std\n",
    "        \n",
    "        if self.transform:\n",
    "            seq = self.transform(seq)\n",
    "            target_seq = self.transform(target_seq)\n",
    "            \n",
    "        return seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3033,  0.2946,  0.2954,  0.2787,  0.2787, -0.0270],\n",
       "          [ 0.2803,  0.2716,  0.2832,  0.2623,  0.2623, -0.3326],\n",
       "          [ 0.2753,  0.3092,  0.2932,  0.3349,  0.3349,  0.8092],\n",
       "          [ 0.3580,  0.3548,  0.3685,  0.3779,  0.3779,  0.6783],\n",
       "          [ 0.3719,  0.3953,  0.3945,  0.3804,  0.3804,  0.5362],\n",
       "          [ 0.3612,  0.3826,  0.3825,  0.4077,  0.4077,  0.3037],\n",
       "          [ 0.4134,  0.4220,  0.4368,  0.4478,  0.4478, -0.2548]]]),\n",
       " tensor([[[ 0.4363,  0.4348,  0.4474,  0.4431,  0.4431,  0.2700],\n",
       "          [ 0.4269,  0.4061,  0.3983,  0.3721,  0.3721,  0.1823],\n",
       "          [ 0.3935,  0.3818,  0.3812,  0.3790,  0.3790, -0.3637],\n",
       "          [ 0.3982,  0.4035,  0.4113,  0.4034,  0.4034, -0.6333],\n",
       "          [ 0.3936,  0.4033,  0.4006,  0.3973,  0.3973, -0.9616],\n",
       "          [ 0.3664,  0.3395,  0.3460,  0.3188,  0.3188, -0.3173],\n",
       "          [ 0.3322,  0.3195,  0.3404,  0.3363,  0.3363, -0.5530]]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(TimeSeriesDataset(n100_train, 7, torchvision.transforms.ToTensor())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = DataLoader(TimeSeriesDataset(n100_train, 7, torchvision.transforms.ToTensor()), batch_size = 1, shuffle = False)\n",
    "x_valid = DataLoader(TimeSeriesDataset(n100_valid, 7, torchvision.transforms.ToTensor()), batch_size = 1, shuffle = False)\n",
    "x_test = DataLoader(TimeSeriesDataset(n100_test, 7, torchvision.transforms.ToTensor()), batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.LSTM1 = torch.nn.LSTM(6, 64, 16)\n",
    "        self.regression = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(64, 64),\n",
    "            torch.nn.BatchNorm1d(7),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(64, 6)\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 7, 6)\n",
    "        x, _ = self.LSTM1(x)\n",
    "        x = torch.nn.BatchNorm1d(7)(x)\n",
    "        x = self.regression(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestModel:\n",
    "    def __init__(self, best_loss = float(\"inf\")):\n",
    "        self.best_loss = best_loss\n",
    "        \n",
    "    def __call__(self, loss, model):\n",
    "        if loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            torch.save(model.state_dict(), \"params/best_model_param\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN()\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.HuberLoss(delta = 0.8)\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "best_model = BestModel()\n",
    "\n",
    "\n",
    "def train(dataloader, valid_dataloader, model, loss_fn, optimizer, function = None):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.reshape(-1, 7, 6).to(device)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(x)\n",
    "            print(f\"loss: {loss:>5f}  [{current:>3d}/{size:>3d}]\")\n",
    "    \n",
    "    model.eval()\n",
    "    num_batches = len(valid_dataloader)\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_dataloader:\n",
    "            x, y = x.to(device), y.reshape(-1, 7, 6).to(device)\n",
    "            pred = model(x)\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "    if function:\n",
    "        function(valid_loss, model)\n",
    "    valid_loss /= num_batches\n",
    "    print(f\"Avg Valid loss: {valid_loss:>8f} \\n\")\n",
    "            \n",
    "    \n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.reshape(-1, 7, 6).to(device)\n",
    "            pred = model(x)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg Test loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.129381  [  1/395]\n",
      "loss: 0.021744  [101/395]\n",
      "loss: 0.009208  [201/395]\n",
      "loss: 0.009691  [301/395]\n",
      "Avg Valid loss: 0.034140 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.364192  [  1/395]\n",
      "loss: 0.014649  [101/395]\n",
      "loss: 0.011849  [201/395]\n",
      "loss: 0.013202  [301/395]\n",
      "Avg Valid loss: 0.037180 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.369181  [  1/395]\n",
      "loss: 0.018537  [101/395]\n",
      "loss: 0.009676  [201/395]\n",
      "loss: 0.012711  [301/395]\n",
      "Avg Valid loss: 0.033765 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.357921  [  1/395]\n",
      "loss: 0.017479  [101/395]\n",
      "loss: 0.029544  [201/395]\n",
      "loss: 0.014135  [301/395]\n",
      "Avg Valid loss: 0.031778 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.341209  [  1/395]\n",
      "loss: 0.045832  [101/395]\n",
      "loss: 0.033730  [201/395]\n",
      "loss: 0.012652  [301/395]\n",
      "Avg Valid loss: 0.034477 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.380833  [  1/395]\n",
      "loss: 0.067433  [101/395]\n",
      "loss: 0.037902  [201/395]\n",
      "loss: 0.012381  [301/395]\n",
      "Avg Valid loss: 0.040521 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.488748  [  1/395]\n",
      "loss: 0.072314  [101/395]\n",
      "loss: 0.038087  [201/395]\n",
      "loss: 0.015837  [301/395]\n",
      "Avg Valid loss: 0.058715 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.477180  [  1/395]\n",
      "loss: 0.047987  [101/395]\n",
      "loss: 0.030426  [201/395]\n",
      "loss: 0.015999  [301/395]\n",
      "Avg Valid loss: 0.033647 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.387199  [  1/395]\n",
      "loss: 0.019807  [101/395]\n",
      "loss: 0.025044  [201/395]\n",
      "loss: 0.013181  [301/395]\n",
      "Avg Valid loss: 0.039922 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.382427  [  1/395]\n",
      "loss: 0.027090  [101/395]\n",
      "loss: 0.031593  [201/395]\n",
      "loss: 0.013989  [301/395]\n",
      "Avg Valid loss: 0.034573 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(x_train, x_valid, model, loss_fn, optimizer, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Test loss: 0.073094 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"params/best_model_param\"))\n",
    "test(x_test, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = torch.tensor((n100_test[-14:].values - mean) / std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.2770e+03, 1.2835e+03, 1.2680e+03, 1.2763e+03, 1.2765e+03,\n",
       "          1.9804e+08],\n",
       "         [1.2639e+03, 1.2704e+03, 1.2548e+03, 1.2636e+03, 1.2637e+03,\n",
       "          2.0061e+08],\n",
       "         [1.2798e+03, 1.2866e+03, 1.2710e+03, 1.2789e+03, 1.2794e+03,\n",
       "          1.9745e+08],\n",
       "         [1.2993e+03, 1.3062e+03, 1.2906e+03, 1.2977e+03, 1.2985e+03,\n",
       "          1.9362e+08],\n",
       "         [1.2798e+03, 1.2867e+03, 1.2713e+03, 1.2787e+03, 1.2796e+03,\n",
       "          1.9742e+08],\n",
       "         [1.2789e+03, 1.2858e+03, 1.2704e+03, 1.2779e+03, 1.2787e+03,\n",
       "          1.9760e+08],\n",
       "         [1.2888e+03, 1.2957e+03, 1.2802e+03, 1.2874e+03, 1.2883e+03,\n",
       "          1.9567e+08]],\n",
       "\n",
       "        [[1.4343e+03, 1.4417e+03, 1.4222e+03, 1.4280e+03, 1.4297e+03,\n",
       "          1.6713e+08],\n",
       "         [1.4177e+03, 1.4250e+03, 1.4057e+03, 1.4120e+03, 1.4135e+03,\n",
       "          1.7039e+08],\n",
       "         [1.4369e+03, 1.4445e+03, 1.4251e+03, 1.4304e+03, 1.4325e+03,\n",
       "          1.6659e+08],\n",
       "         [1.4616e+03, 1.4694e+03, 1.4498e+03, 1.4543e+03, 1.4566e+03,\n",
       "          1.6172e+08],\n",
       "         [1.4356e+03, 1.4434e+03, 1.4241e+03, 1.4290e+03, 1.4314e+03,\n",
       "          1.6680e+08],\n",
       "         [1.4346e+03, 1.4423e+03, 1.4231e+03, 1.4280e+03, 1.4304e+03,\n",
       "          1.6701e+08],\n",
       "         [1.4475e+03, 1.4553e+03, 1.4359e+03, 1.4405e+03, 1.4429e+03,\n",
       "          1.6448e+08]]], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = (model(test_example) * torch.tensor(std)) + torch.tensor(mean)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.376540e+03, 1.383100e+03, 1.372070e+03, 1.381640e+03,\n",
       "        1.381640e+03, 3.020746e+08],\n",
       "       [1.382410e+03, 1.388590e+03, 1.380170e+03, 1.388490e+03,\n",
       "        1.388490e+03, 2.871619e+08],\n",
       "       [1.388240e+03, 1.388430e+03, 1.381150e+03, 1.387250e+03,\n",
       "        1.387250e+03, 2.351059e+08],\n",
       "       [1.387600e+03, 1.394100e+03, 1.387580e+03, 1.390510e+03,\n",
       "        1.390510e+03, 2.320258e+08],\n",
       "       [1.390160e+03, 1.390160e+03, 1.365260e+03, 1.375220e+03,\n",
       "        1.375220e+03, 3.159345e+08],\n",
       "       [1.375330e+03, 1.402670e+03, 1.375330e+03, 1.401480e+03,\n",
       "        1.401480e+03, 3.911457e+08],\n",
       "       [1.400680e+03, 1.403500e+03, 1.391240e+03, 1.400610e+03,\n",
       "        1.400610e+03, 4.174905e+08]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n100_test[-7:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.2309,  7.1978,  7.5865,  7.6269,  7.6098, 34.4399],\n",
       "         [ 8.5700,  8.5145,  9.0810,  8.9914,  8.9866, 30.1396],\n",
       "         [ 7.8088,  7.3368,  7.9720,  7.8110,  7.7720, 16.0154],\n",
       "         [ 6.3632,  6.3049,  6.9883,  6.6746,  6.6185, 16.5514],\n",
       "         [ 7.9397,  7.4413,  6.8843,  7.0180,  6.9539, 37.5110],\n",
       "         [ 7.0094,  8.3293,  7.6299,  8.8188,  8.7580, 49.4830],\n",
       "         [ 7.9886,  7.6793,  7.9801,  8.0794,  8.0172, 53.1325]],\n",
       "\n",
       "        [[ 4.1937,  4.2341,  3.6558,  3.3542,  3.4815, 44.6711],\n",
       "         [ 2.5533,  2.6192,  1.8470,  1.6928,  1.8048, 40.6630],\n",
       "         [ 3.5042,  4.0359,  3.1813,  3.1109,  3.2596, 29.1432],\n",
       "         [ 5.3340,  5.4009,  4.4851,  4.5866,  4.7557, 30.2990],\n",
       "         [ 3.2687,  3.8278,  4.3100,  3.9128,  4.0866, 47.2033],\n",
       "         [ 4.3080,  2.8276,  3.4707,  1.8958,  2.0642, 57.3034],\n",
       "         [ 3.3403,  3.6881,  3.2073,  2.8507,  3.0226, 60.6021]]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#losses/percent errors\n",
    "diff = torch.abs(pred - torch.tensor(n100_test[-7:].values))\n",
    "(diff / torch.abs(torch.tensor(n100_test[-7:].values)) * torch.tensor(100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
