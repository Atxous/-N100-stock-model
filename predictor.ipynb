{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/2008_Global_Markets_Data.csv\")\n",
    "for x in (2009, 2023):\n",
    "    df = pd.concat([df, pd.read_csv(f\"data/{x}_Global_Markets_Data.csv\")], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.set_index(\"Date\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8*len(df))\n",
    "\n",
    "x_train = df.select_dtypes(include = np.number)[:train_size].astype(np.float32)\n",
    "x_valid = df.select_dtypes(include = np.number)[train_size:int(0.9*len(df))].astype(np.float32)\n",
    "x_test = df.select_dtypes(include = np.number)[int(0.9*len(df)):].astype(np.float32)\n",
    "\n",
    "x_train[\"Ticker\"] = df[\"Ticker\"][:train_size]\n",
    "x_valid[\"Ticker\"] = df[\"Ticker\"][train_size:int(0.9*len(df))]\n",
    "x_test[\"Ticker\"] = df[\"Ticker\"][int(0.9*len(df)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n100_train = x_train[x_train[\"Ticker\"] == \"^N100\"].drop(\"Ticker\", axis = 1)\n",
    "n100_valid = x_valid[x_valid[\"Ticker\"] == \"^N100\"].drop(\"Ticker\", axis = 1)\n",
    "n100_test = x_test[x_test[\"Ticker\"] == \"^N100\"].drop(\"Ticker\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = n100_train.values.mean(0), n100_train.values.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, input_seq, window_length, transform = None):\n",
    "        self.input_seq = input_seq\n",
    "        self.window_length = window_length\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_seq) - self.window_length * 2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        window = idx + self.window_length\n",
    "        seq = (np.array(self.input_seq[idx:window]) - mean) / std\n",
    "        target_seq = (np.array(self.input_seq[window:window + self.window_length]) - mean) / std\n",
    "        \n",
    "        if self.transform:\n",
    "            seq = self.transform(seq)\n",
    "            target_seq = self.transform(target_seq)\n",
    "            \n",
    "        return seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3033,  0.2946,  0.2954,  0.2787,  0.2787, -0.0270],\n",
       "          [ 0.2803,  0.2716,  0.2832,  0.2623,  0.2623, -0.3326],\n",
       "          [ 0.2753,  0.3092,  0.2932,  0.3349,  0.3349,  0.8092],\n",
       "          [ 0.3580,  0.3548,  0.3685,  0.3779,  0.3779,  0.6783],\n",
       "          [ 0.3719,  0.3953,  0.3945,  0.3804,  0.3804,  0.5362],\n",
       "          [ 0.3612,  0.3826,  0.3825,  0.4077,  0.4077,  0.3037],\n",
       "          [ 0.4134,  0.4220,  0.4368,  0.4478,  0.4478, -0.2548]]]),\n",
       " tensor([[[ 0.4363,  0.4348,  0.4474,  0.4431,  0.4431,  0.2700],\n",
       "          [ 0.4269,  0.4061,  0.3983,  0.3721,  0.3721,  0.1823],\n",
       "          [ 0.3935,  0.3818,  0.3812,  0.3790,  0.3790, -0.3637],\n",
       "          [ 0.3982,  0.4035,  0.4113,  0.4034,  0.4034, -0.6333],\n",
       "          [ 0.3936,  0.4033,  0.4006,  0.3973,  0.3973, -0.9616],\n",
       "          [ 0.3664,  0.3395,  0.3460,  0.3188,  0.3188, -0.3173],\n",
       "          [ 0.3322,  0.3195,  0.3404,  0.3363,  0.3363, -0.5530]]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(TimeSeriesDataset(n100_train, 7, torchvision.transforms.ToTensor())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = DataLoader(TimeSeriesDataset(n100_train, 7, torchvision.transforms.ToTensor()), batch_size = 1, shuffle = False)\n",
    "x_valid = DataLoader(TimeSeriesDataset(n100_valid, 7, torchvision.transforms.ToTensor()), batch_size = 1, shuffle = False)\n",
    "x_test = DataLoader(TimeSeriesDataset(n100_test, 7, torchvision.transforms.ToTensor()), batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.LSTM1 = torch.nn.LSTM(6, 64, 16)\n",
    "        self.regression = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(64, 64),\n",
    "            torch.nn.BatchNorm1d(7),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(64, 6)\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 7, 6)\n",
    "        x, _ = self.LSTM1(x)\n",
    "        x = torch.nn.BatchNorm1d(7)(x)\n",
    "        x = self.regression(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestModel:\n",
    "    def __init__(self, best_loss = float(\"inf\")):\n",
    "        self.best_loss = best_loss\n",
    "        \n",
    "    def __call__(self, loss, model):\n",
    "        if loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "            torch.save(model.state_dict(), \"params/best_model_param\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN()\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.HuberLoss(delta = 0.8)\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "best_model = BestModel()\n",
    "\n",
    "\n",
    "def train(dataloader, valid_dataloader, model, loss_fn, optimizer, function = None):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.reshape(-1, 7, 6).to(device)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(x)\n",
    "            print(f\"loss: {loss:>5f}  [{current:>3d}/{size:>3d}]\")\n",
    "    \n",
    "    model.eval()\n",
    "    num_batches = len(valid_dataloader)\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_dataloader:\n",
    "            x, y = x.to(device), y.reshape(-1, 7, 6).to(device)\n",
    "            pred = model(x)\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "    if function:\n",
    "        function(valid_loss, model)\n",
    "    valid_loss /= num_batches\n",
    "    print(f\"Avg Valid loss: {valid_loss:>8f} \\n\")\n",
    "            \n",
    "    \n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.reshape(-1, 7, 6).to(device)\n",
    "            pred = model(x)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg Test loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.259609  [  1/395]\n",
      "loss: 0.018820  [101/395]\n",
      "loss: 0.011673  [201/395]\n",
      "loss: 0.011512  [301/395]\n",
      "Avg Valid loss: 0.032891 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.366077  [  1/395]\n",
      "loss: 0.015175  [101/395]\n",
      "loss: 0.008586  [201/395]\n",
      "loss: 0.011848  [301/395]\n",
      "Avg Valid loss: 0.032504 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.376228  [  1/395]\n",
      "loss: 0.014558  [101/395]\n",
      "loss: 0.020074  [201/395]\n",
      "loss: 0.012281  [301/395]\n",
      "Avg Valid loss: 0.033749 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.367871  [  1/395]\n",
      "loss: 0.018627  [101/395]\n",
      "loss: 0.028128  [201/395]\n",
      "loss: 0.014391  [301/395]\n",
      "Avg Valid loss: 0.033292 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.364536  [  1/395]\n",
      "loss: 0.036430  [101/395]\n",
      "loss: 0.031949  [201/395]\n",
      "loss: 0.013180  [301/395]\n",
      "Avg Valid loss: 0.035412 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.397788  [  1/395]\n",
      "loss: 0.035560  [101/395]\n",
      "loss: 0.032085  [201/395]\n",
      "loss: 0.013703  [301/395]\n",
      "Avg Valid loss: 0.033713 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.377190  [  1/395]\n",
      "loss: 0.030303  [101/395]\n",
      "loss: 0.036083  [201/395]\n",
      "loss: 0.013633  [301/395]\n",
      "Avg Valid loss: 0.033529 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.364606  [  1/395]\n",
      "loss: 0.043208  [101/395]\n",
      "loss: 0.034036  [201/395]\n",
      "loss: 0.013441  [301/395]\n",
      "Avg Valid loss: 0.032723 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.441329  [  1/395]\n",
      "loss: 0.022150  [101/395]\n",
      "loss: 0.035685  [201/395]\n",
      "loss: 0.012613  [301/395]\n",
      "Avg Valid loss: 0.053911 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.378575  [  1/395]\n",
      "loss: 0.036214  [101/395]\n",
      "loss: 0.036618  [201/395]\n",
      "loss: 0.013598  [301/395]\n",
      "Avg Valid loss: 0.036106 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(x_train, x_valid, model, loss_fn, optimizer, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Test loss: 0.075570 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"params/best_model_param\"))\n",
    "test(x_test, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = torch.tensor((n100_test[-14:-7].values - mean) / std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.3652e+03, 1.3793e+03, 1.3616e+03, 1.3698e+03, 1.3653e+03,\n",
       "          1.7611e+08],\n",
       "         [1.3434e+03, 1.3567e+03, 1.3406e+03, 1.3474e+03, 1.3434e+03,\n",
       "          1.8022e+08],\n",
       "         [1.3661e+03, 1.3801e+03, 1.3628e+03, 1.3708e+03, 1.3665e+03,\n",
       "          1.7611e+08],\n",
       "         [1.3450e+03, 1.3585e+03, 1.3417e+03, 1.3489e+03, 1.3446e+03,\n",
       "          1.7973e+08],\n",
       "         [1.3647e+03, 1.3788e+03, 1.3612e+03, 1.3693e+03, 1.3649e+03,\n",
       "          1.7625e+08],\n",
       "         [1.3434e+03, 1.3570e+03, 1.3401e+03, 1.3473e+03, 1.3430e+03,\n",
       "          1.8000e+08],\n",
       "         [1.3477e+03, 1.3614e+03, 1.3444e+03, 1.3517e+03, 1.3474e+03,\n",
       "          1.7923e+08]]], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = (model(test_example) * torch.tensor(std)) + torch.tensor(mean)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.376540e+03, 1.383100e+03, 1.372070e+03, 1.381640e+03,\n",
       "        1.381640e+03, 3.020746e+08],\n",
       "       [1.382410e+03, 1.388590e+03, 1.380170e+03, 1.388490e+03,\n",
       "        1.388490e+03, 2.871619e+08],\n",
       "       [1.388240e+03, 1.388430e+03, 1.381150e+03, 1.387250e+03,\n",
       "        1.387250e+03, 2.351059e+08],\n",
       "       [1.387600e+03, 1.394100e+03, 1.387580e+03, 1.390510e+03,\n",
       "        1.390510e+03, 2.320258e+08],\n",
       "       [1.390160e+03, 1.390160e+03, 1.365260e+03, 1.375220e+03,\n",
       "        1.375220e+03, 3.159345e+08],\n",
       "       [1.375330e+03, 1.402670e+03, 1.375330e+03, 1.401480e+03,\n",
       "        1.401480e+03, 3.911457e+08],\n",
       "       [1.400680e+03, 1.403500e+03, 1.391240e+03, 1.400610e+03,\n",
       "        1.400610e+03, 4.174905e+08]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n100_test[-7:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8260,  0.2733,  0.7638,  0.8562,  1.1803, 41.6993],\n",
       "         [ 2.8213,  2.2980,  2.8663,  2.9589,  3.2508, 37.2420],\n",
       "         [ 1.5970,  0.6017,  1.3322,  1.1828,  1.4981, 25.0951],\n",
       "         [ 3.0724,  2.5516,  3.3052,  2.9952,  3.3003, 22.5402],\n",
       "         [ 1.8338,  0.8194,  0.3006,  0.4277,  0.7509, 44.2135],\n",
       "         [ 2.3198,  3.2579,  2.5597,  3.8694,  4.1724, 53.9820],\n",
       "         [ 3.7813,  3.0031,  3.3640,  3.4913,  3.7962, 57.0694]]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#losses/percent errors\n",
    "diff = torch.abs(pred - torch.tensor(n100_test[-7:].values))\n",
    "(diff / torch.abs(torch.tensor(n100_test[-7:].values)) * torch.tensor(100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
